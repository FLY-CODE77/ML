{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 안녕 내이름은 플코, \n",
    "# 17기 수학 정복\n",
    "- 1번 퀴즈! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. BASIC 문제 \n",
    "\n",
    "- $x_1 + x_2 + x_3 = 3$ \n",
    "\n",
    "#### 다음과 같은 식들을 무엇이라고 부를까요 ?(문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Matrix \n",
    "- A = np.array([[1, 2, 3], [3, 2, 1]])\n",
    "- B = np.array([[0, 1, 0], [2, 1, 1]])\n",
    "\n",
    "#### 행렬의 내적 AB = BA가 다름을 증명하세요 !(문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Inverse and Transpose \n",
    "\n",
    "- A = np.array([[a, b], [c, d]])\n",
    "\n",
    "#### $A^t, A^{-1}$ 을 적어주세요!!(문제)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. inverse part2 \n",
    "- 역행렬의 정의는 무엇일까요?!\n",
    "- art of Symmetirc \n",
    "    - symmetric 행렬은 어떤 행렬일까용?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 많이 하는 실수 \n",
    "\n",
    "- a : $(A + B)^{-1} = A^{-1} + B^{-1}$\n",
    "- b : $(AB)^{-1} = A^{-1} B^{-1}$\n",
    "- c : $(A + B)^{T} = A^{T} + B^{T}$\n",
    "- d : $(AB)^{T} = A^{T} B^{T}$\n",
    "---\n",
    "#### a, b, c, d 중 틀린 식은 어떤것일까요?(문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 어려운 계산 문제 ?\n",
    "---\n",
    "- 0이 아닌 행과 열을 A nonzero row or columns 이라고 합니다 \n",
    "- *행*의 제일 윈쪽에 있는 0이 아닌 원소를 nonzero entry를 : 행의 선행 성분 leading entry of row 라고 합니다 \n",
    "---\n",
    "- 사다리꼴 - Echelon form이란 \n",
    "    - 모든 nonzero row는 all zeros row 보다 위에 있습니다\n",
    "    - 행의 leading entry는 위에 있는 leading entry 보다 오른쪽 열에 있습니다 \n",
    "---\n",
    "- 기약 행 사다리꼴 - Reduced echelon form\n",
    "    - 기존 echelon form 에서 조금의 조건이 더해집니다\n",
    "    - nonzeror 행에 있는 leading entry 는 1입니다\n",
    "    - leading entry가 1인 부분을 제외하고는 그 *열*은 모두 0이여야 합니다 \n",
    "---\n",
    "- Reduced echelon form 을 왜 구지 만들까요..? 넘나 힘든데?\n",
    "- unique!!! - 각각의 행렬에서 Reduced echelon form은 하나 뿐이 없습니다!!\n",
    "- 그래서 나중에 역행렬을 구하거나 ..?/ 선형독립인지 확인/ 더 나아가 rank를 확인할때 매우 important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "- 본 게임 위 설명의 행과 열이라는 단어를 주의 깊게 보시고 이제 문제를 풀어 보겠나이다~?\n",
    "\n",
    "- 행 줄임 알고리즘 - Row reduction algorithms (우리를 괴롭혔던?!)\n",
    "- 행 줄임 알고리즘을 이용해서 우리가 Reduced echelon form을 만들어 봅시다.\n",
    "\n",
    "###  Reduced echelon form 만들기를 해봅시다 (문제)\n",
    "- A = np.array(\n",
    "               [[0, 3, -6, 6, 5, -5],\n",
    "               [ 3, -7, 8, -5, 8, 9],\n",
    "              [3, -9, 12, -9, 6 , 15]])\n",
    "- 라는 끔찍한 행렬이 있을때\n",
    "---\n",
    "- step1 : 가장 왼쪽에 있는 열은 nonzero열에서 시작하고\n",
    "        - 가장 왼쪽의 열을 pivot columnss 이라고 불르고, 열의 첫번째 성분을 pivot position이라고 합니다.\n",
    "        - pivot position을 0이 안되게 interchange 해줍시다\n",
    "        \n",
    "---\n",
    "- step2 : pivot position 아래의 항목을 모두 0이 되도록 만들어 줍시다! \n",
    "    - 이 과정을 row reduction 과정이라고 합니다 (TMI)\n",
    "    \n",
    "---\n",
    "- step3 : 위 과정을 pivot columns 들을 돌아가면서 동일하게 합시다! \n",
    "---\n",
    "- step4 : 맨 아래 pivot position(혹은 pivot)을 1로 만들고 pivot 위도 다 0으로 만들어 줍시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 문제 아님 ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 그럼 이걸 왜 쓸까?!\n",
    "- 선형 시스템에서 자유변수 가 없다면 해가 하나입니다!, 자유 변수가 있다면 해는 무수히 많습니다.\n",
    "\n",
    "- 만약 reduced echelon form 의 첨가행렬이!\n",
    "- np.array(\n",
    "          [[1, 0,-5, 1],\n",
    "           [0, 1, 1, 4],\n",
    "           [0, 0, 0, 0]]) 으로 나왔다면\n",
    "\n",
    "- 선형 방적식으로는 \n",
    "- $ x_1 - 5x_3 = 1$, $x_2 +x_3 =4, 0 = 0\n",
    "\n",
    "---\n",
    "\n",
    "- 해는\n",
    "- $x_1 = 1 + 5x_3$\n",
    "- $x_2 = 4 - x_3$\n",
    "- x_3 는 자유 변수 입니다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 일반해(general solution)은 보통 basic variables 와 free variables 로 표현된 식입니다 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제 다시 시작!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. ### algorithms for solving linear equations(Moore-Penrose pseudo-inverse)\n",
    "\n",
    "- Ax= b 가 있을때 만약 A가 역행렬이 있을지 잘 모르겠다면(A가 정방행렬이며 역행렬 가능 한 경우가 생각보다 없으요)\n",
    "- A는 선형 독립 컬럼들로 구성되어 있습니다.\n",
    "---\n",
    "- #### x를 어떻게 풀수 있을까요!?(문제)  이차형식 , Quadratic Form\n",
    "\n",
    "- tip \n",
    "- $A^tA$ 대칭행렬과 원 행렬을 곱하면 항상 역행렬이 가능합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tip\n",
    "- 이차형식이 > 0 크면 양의 정부호 (positive definite)\n",
    "- 이차형식 >= 0 이면 양의 준정부호 (positivie semi-definite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Group Theory  \n",
    "- https://www.youtube.com/watch?v=mH0oCDa74tE : 나중에 한번 봅시더 \n",
    "        \n",
    "---\n",
    "- vector 들로 만들어진 공간을 _______ 라고 합니다\n",
    "- ##### 빈칸을 채워주세요 (문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. linear independence는 \n",
    "#### linear independence는 무엇을 의미할까요~? (문제)\n",
    "#### rank는 무엇을 의미하는것일까요 (문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 . Affine transformation \n",
    "##### affine 변환은 무엇을 의미합니까!!!!(문제)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 추가로 알아두면 좋은것들?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미지수의 수와 방정식의 수\n",
    "- 방정식의 수와 미지수의 수가 같다 (N = M)\n",
    "- 방정식의 수가 미지수의 수 보다 적다 (N < M)\n",
    "- 방정식의 수가 미지수의 수 보다 크다 (N > M)\n",
    "\n",
    "- 1번 같은 경우는 해를 구할수 있지만\n",
    "- 2, 3 번 같은 경우는 해를 구할수가 없다 \n",
    "\n",
    "- 보통 선형 회귀 데이터의 수는 입력 차원보다 큰 경우가 많다 \n",
    "- 이 경우 방정식의 수가 미지수 수보다 많다 !\n",
    "\n",
    "## 최소 자승 문제 \n",
    "- 보통의 우리의 선형회귀 데이터 같은 경우은... 우찌 해를 구해야 할까?\n",
    "- 정답 최대한 비슷한 값을 예측해준다!!!\n",
    "---\n",
    "- 예측값과 목표값의 차이를 잔차 )residual 라고 하는데\n",
    "- 최소 자승 문제는 벡터의 크기중에서 잔차의 놈의 최소화 하는 문제를 푼다 \n",
    "\n",
    "x=argminxeTe=argminx(Ax−b)T(Ax−b)\n",
    "\n",
    "- 최소 자승문제\n",
    "\n",
    "$ x = arg min_x e^t e = arg min_x (Ax-b)^T(Ax-b)$\n",
    "\n",
    "$ A^T A$가 항상 정방행렬이 된다는 점을 사용해서\n",
    "\n",
    "- Ax = b\n",
    "- $A^T Ax = A^Tb$\n",
    "- $A^T A$가 역행렬이 존재한다면!\n",
    "- $(A^T A)^{-1}(A^T A)x = (A^T A)^{-1}A^Tb$\n",
    "\n",
    "- 정리하자면!\n",
    "\n",
    "x = $((A^TA)^{-1}A^T)b$\n",
    "\n",
    "- $((A^TA)^{-1}A^T)$ : 의사 역행렬(pseudo inverse) $A^{+}$라고 표기한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 코사인 유사도  vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cosine similarity = cos($\\theta$) = $\\frac{X^Ty}{||x||||y||}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 코사인 유사도 사용자의 취향이 얼마나 비슷한지를 계산할때 사용\n",
    "- cosine distance = 1 - consine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 벡터의 내적과 삼각함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 두 벡터의 내적\n",
    "- 두 벡터 사이의 각도 $\\theta$의 코사인 함수값으로 계산할수 있다.\n",
    "- $a^Tb = ||a||||b||cos{\\theta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 직교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 직교(orthogonal)\n",
    "- 직교하면 cos90 --> 0임으로\n",
    "- $a^Tb =b^Ta$ = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정규 직교 \n",
    "- orthonormal\n",
    "- 단위벡터 n개의 서로 직교 하면 정규직교 orthonormal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형 종속과 선형 독립 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- linear dependent: 선형 종속(linearly dependent)\n",
    "---\n",
    "##### 선형 종속\n",
    "- 벡터의 선형 조합이 0 벡터가 되면서 \n",
    "- $c_1x_1+ c_2x_2 + --- + c_nx_n = 0$\n",
    "- c의 계수가 모두 0이 아닌 경우를 제외하면 이 폼을 선형종속이라고 한다 \n",
    "---\n",
    "##### 선형 독립\n",
    "- 벡터의 선형 조합이 0이 되면서 모두 0이 아닌 계수가 존재하지 않으면 선형 독립이라고 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 선형종속\n",
    "- 특징 행렬 x의 열벡터들이 선형 종속이거나, 선형 종속에 가까운 현상을 multicollinearity 라고 한다\n",
    "- 분석 모델의 성능이 매우 급감한다 \n",
    "---\n",
    "- 경우 1 : 벡터의 갯수가 벡터의 차원 보다 크면 선형 종속\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 경우 2: 값이 같은 벡터가 있으면 반드시 선형 종속입니다 // 실수배로 같은 벡터가 있어도 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 경우3 : 어떤 벡터가 다른 벡터의 선형 조합이면 반드시 선형 종속 이다 \n",
    "    - ex) 국어, 영어 수학 점수를 별도의 데이터로 포함하면서 총점수나 평균을 데이터에 다시 포함하면 선형 종속이 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 랭크 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 행렬의 열벡터 중 서로 독립인 열벡터의 최대 개수를 column rank(열 랭크)라고 한다 \n",
    "- 서로 독립인 행 벡터의 최대 개수를 row rank(행 랭크)라고 한다\n",
    "#### 행랭크와 열랭크는 항상 같다\n",
    "- 따라서 행 랭크나 열랭크를 그냥 랭크(rank)라고 하기도 한다.\n",
    "- 기호는 rankA\n",
    "- 행의 갯수가 n이고 열의 갯수가 m인 행렬의 랭크는 행의 갯수 n과 열의 갯수 m 중에 작은 값보다 커질수 없다\n",
    "- rankA <= mins(M,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### code\n",
    "import numpy as np\n",
    "x1 = np.array([[1,3], [2, 4]])\n",
    "np.linalg.matrix_rank(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 풀랭크 \n",
    "- 행의 개수와 열의 갯수 중 작은값과 같으면 full rank(풀랭크) 라고 한다\n",
    "- rankA = min(m,n)\n",
    "- 선형 독립인 벡터들의 행 또는 열로 가지는 행렬을 만들면 항상 풀랭크이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.array([[1,5,6], [2,6,8],[3,11,14], [1,4,8]])\n",
    "np.linalg.matrix_rank(x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로우 랭크 행렬 \n",
    "\n",
    "- n 차원 벡터 x 하나를 이용하여 만들어지는 행렬을 랭크-1(rank-1 matrix)라고 한다 \n",
    "- 랭크-1 행렬의 랭크는 1이다\n",
    "\n",
    "- 선형 독립인 두개의 n 차원 벡터 x, x2 를 이용한 행렬은 랭크-2 행렬이라고 한다 ..\n",
    "- m개의 n 차원 벡터를 이용하면 랭크-m 행렬\n",
    "- 위에 것들이 로우 랭크 행렬 인데 \n",
    "- 나중에 singular value decompostion, pca 에 사용된다\n",
    "\n",
    "# 벡터 공간과 기저벡터 \n",
    "\n",
    "- 여러 벡터를 선형 조합 하면 다른 벡터를 만들수 있다\n",
    "- 벡터 n개가 선형이라면, 이벡터들을 선형 조합하여 만들어지는 모든 벡터들의 집합을 vector space(V)라고 하고 \n",
    "- 벡터 공간의 차원을 n 이라고 한다 \n",
    "- 그리고 벡터공간의 벡터들을 basis vector 라고 한다 \n",
    "\n",
    "# 랭크와 역행렬\n",
    "\n",
    "- 정방행렬이 풀랭크 이면 역행렬이 존재한다 \n",
    "- 정방행렬의 역행렬이 존재하면 플렝크이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
